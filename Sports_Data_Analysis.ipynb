{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Sports Data Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c00934dd"
      },
      "source": [
        "# **Problem Statement:**\n",
        "\n",
        "- The major objective of this project is to extract actionable insights from the historical match data and make strategic changes to make India win. \n",
        "- Primary objective is to create Machine Learning models which correctly predicts a win for the Indian Cricket Team. \n",
        "- Once a model is developed then you have to extract actionable insights and recommendation. Also, below are the details of the next 10 matches, India is going to play. You have to predict the result of the matches.\n"
      ],
      "id": "c00934dd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROyEYF3443GP",
        "scrolled": true
      },
      "source": [
        "!pip install optuna\n",
        "!pip install xgboost"
      ],
      "id": "ROyEYF3443GP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "304fc73d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import display\n",
        "plt.rcParams['figure.figsize'] = (16,8)\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "\n",
        "from sklearn.model_selection import KFold,StratifiedKFold, train_test_split\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from xgboost import  XGBClassifier\n",
        "\n",
        "\n",
        "import optuna"
      ],
      "id": "304fc73d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "228564cc"
      },
      "source": [
        "# If read.excel doesnt work uncomment and run following code.\n",
        "!pip install xlrd\n",
        "\n"
      ],
      "id": "228564cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8lYVugJu66o"
      },
      "source": [
        "# **Loading the data**\n",
        "\n",
        "### Data Dictionary"
      ],
      "id": "-8lYVugJu66o"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92db46c6"
      },
      "source": [
        "df_metadata = pd.read_excel('/content/Sports Data.xlsx', sheet_name = 'Meta data', header = 1, usecols = [1,2])\n",
        "df_metadata"
      ],
      "id": "92db46c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44383bd2"
      },
      "source": [
        "## Data set"
      ],
      "id": "44383bd2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19eff2e7"
      },
      "source": [
        "df_maindata_excel = pd.read_excel('/content/Sports Data.xlsx', sheet_name = 'Sports data for DSBA')\n",
        "df_maindata_excel.info()"
      ],
      "id": "19eff2e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29LUYwz77pwd"
      },
      "source": [
        "## **Creating StratifyKFold columns in the dataset, which will be used to create train, validation split in later stages.**"
      ],
      "id": "29LUYwz77pwd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYqumf6Rtfai"
      },
      "source": [
        "df_maindata_excel[\"kfold\"] = -1\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for fold, (train_indicies, valid_indicies) in enumerate(skf.split(df_maindata_excel, df_maindata_excel.Result)):\n",
        "    df_maindata_excel.loc[valid_indicies, \"kfold\"] = fold\n",
        "\n",
        "df_maindata_excel.to_csv(\"maindata_folds.csv\", index=False)"
      ],
      "id": "JYqumf6Rtfai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a1JSid0HEGr"
      },
      "source": [
        "df_maindata = pd.read_csv('maindata_folds.csv')\n",
        "df_maindata.head()"
      ],
      "id": "6a1JSid0HEGr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00bc32a3"
      },
      "source": [
        "df_maindata.shape"
      ],
      "id": "00bc32a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1z42ib4T3Ql"
      },
      "source": [
        "df_maindata.describe()"
      ],
      "id": "T1z42ib4T3Ql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3400df45"
      },
      "source": [
        "df_maindata.info()"
      ],
      "id": "3400df45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6d614f5"
      },
      "source": [
        "Observations:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- There are missing values. Check them and treat them accordingly\n",
        "- Player_hightest_wicket and Players_scored_zero is object type convert it into int as it might be useful as int\n"
      ],
      "id": "b6d614f5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v21UXqH6RSH6"
      },
      "source": [
        "\"\"\"Making columns lower case and replacing any spaces with '_'\"\"\"\n",
        "df_maindata.columns = df_maindata.columns.str.lower().str.replace(' ', '_')"
      ],
      "id": "v21UXqH6RSH6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufpyOJI-Oruf"
      },
      "source": [
        "## **Check unique values and convert required columns into Integer type:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Check the unique values \n",
        "- If all values are int then we change it to integer\n",
        "- Else we convert any string values to int and then convert all values into int type."
      ],
      "id": "ufpyOJI-Oruf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-FOFoPSOfkq"
      },
      "source": [
        "for col in df_maindata.columns:\n",
        "  print(col, '\\n',df_maindata[col].unique())\n",
        "  print()"
      ],
      "id": "p-FOFoPSOfkq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK3IR2AlQFra"
      },
      "source": [
        "### **Observations:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Variables like player_highest_wicket, players_scored_zero, match_format, first_selection has repeated unique values. \n",
        "- E.g. player_highest_wicket has 'Three' and 3, which actually means the same. Hence, we will replace 'Three' by 3.\n",
        "- Similarly for the other variables.\n",
        "- Finally convert player_hightest_wicket and players_scored_zero to integer"
      ],
      "id": "HK3IR2AlQFra"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvu2T-ArQgLs"
      },
      "source": [
        "\"\"\"Replacing repeated values\"\"\"\n",
        "\n",
        "df_maindata['player_highest_wicket'] = df_maindata['player_highest_wicket'].apply(lambda x: x if (x != 'Three') else 3)\n",
        "df_maindata['players_scored_zero'] = df_maindata['players_scored_zero'].apply(lambda x: x if (x != 'Three') else 3)\n",
        "df_maindata['match_format'] = df_maindata['match_format'].apply(lambda x: x if (x != '20-20') else 'T20')\n",
        "df_maindata['first_selection'] = df_maindata['first_selection'].apply(lambda x: x if (x != 'Bat') else 'Batting')\n",
        "\n",
        "\n",
        "\"\"\"Converting player_highest_wicket and players_scored_zero to integer\"\"\"\n",
        "df_maindata['player_highest_wicket'] = df_maindata['player_highest_wicket'].astype('int')\n",
        "df_maindata['players_scored_zero'] = df_maindata['players_scored_zero'].astype('int')\n",
        "\n",
        "for col in df_maindata.columns:\n",
        "  print(col, '\\n',df_maindata[col].unique())\n",
        "  print()"
      ],
      "id": "Qvu2T-ArQgLs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b71968a"
      },
      "source": [
        "df_maindata.isnull().sum().to_frame().rename({0: 'Missing Values'}, axis = 1).sort_values(by = 'Missing Values', ascending = False).style.background_gradient('copper_r')"
      ],
      "id": "7b71968a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79fb16f4",
        "scrolled": true
      },
      "source": [
        "\"\"\"Percentage of Missing Values\"\"\"\n",
        "percentage = df_maindata.isnull().mean().round(5).to_frame().rename({0: '%age of Missing Values'}, axis = 1).sort_values(by = '%age of Missing Values', ascending = False)\n",
        "display(percentage.style.background_gradient('copper_r'))\n",
        "\n",
        "\"\"\"Setting for displaying plot\"\"\"\n",
        "plot_percentage = percentage.reset_index().rename({\"index\": \"Variables\"}, axis = 1)\n",
        "# order = percentage.isnull().mean().round(2).sort_values(ascending =False).index\n",
        "ax = sns.barplot(plot_percentage['%age of Missing Values'], plot_percentage['Variables'], palette = 'copper')\n",
        "plt.show()"
      ],
      "id": "79fb16f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a3e27d0"
      },
      "source": [
        "Observations:\n",
        "- Missing values in Avg_team_Age, Bowlers_in_team, Audience_number,Match_format ,Offshore, Season,First_selection, Match_light_type ,All_rounder_in_team, Opponent,Max_run_given_1over, Extra_bowls_bowled,player_highest_run,Max_run_scored_1over, Min_run_scored_1over Treat them accordingly\n",
        "- Avg_team_Age has highest number of missing values.\n",
        "- **Missing value in Opponent cannot be filled with mode as it might bias our result towards. Best option is to drop those rows**"
      ],
      "id": "3a3e27d0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40b0f547",
        "scrolled": true
      },
      "source": [
        "missing_values_cols = list(plot_percentage[plot_percentage['%age of Missing Values'] != 0]['Variables']) \n",
        "missing_cat_cols = [col for col in missing_values_cols if df_maindata[col].dtype == 'object']\n",
        "missing_num_cols = [col for col in missing_values_cols if col not in missing_cat_cols]\n",
        "missing_cat_cols"
      ],
      "id": "40b0f547",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eee2da8a",
        "scrolled": true
      },
      "source": [
        "\"\"\"Drop rows with missing values in Opponent\"\"\"\n",
        "df_maindata.dropna(subset=['opponent'], inplace = True)\n",
        "\n",
        "# Now removing Opponent col from list of categorical colummns\n",
        "missing_cat_cols.remove('opponent')                     \n",
        "\n",
        "\"\"\"Impute Mode for categorical columns\"\"\"\n",
        "for col in missing_cat_cols:\n",
        "    df_maindata[col].fillna(value=df_maindata[col].mode()[0],inplace=True)\n",
        "\n",
        "\"\"\"Impute mean for numerical columns\"\"\"\n",
        "for col in missing_num_cols:\n",
        "    df_maindata[col].fillna(value=df_maindata[col].median(),inplace=True)"
      ],
      "id": "eee2da8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74e2e23a",
        "scrolled": false
      },
      "source": [
        "df_maindata.isnull().sum().to_frame().rename({0: 'Missing Values'}, axis = 1).sort_values(by = 'Missing Values', ascending = False).style.background_gradient('copper_r')"
      ],
      "id": "74e2e23a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d4e43b8"
      },
      "source": [
        "Observations:\n",
        "- Dropped the rows with missing values in Opponent Col \n",
        "- Imputed categorical missing values using mode\n",
        "- Imputed numerical missing values using mean"
      ],
      "id": "3d4e43b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaUmuMA-7j7a"
      },
      "source": [
        "## **Duplicates?**"
      ],
      "id": "jaUmuMA-7j7a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxOWv_uh7qjH"
      },
      "source": [
        "df_maindata.duplicated().sum()"
      ],
      "id": "XxOWv_uh7qjH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7avb0S27xJp"
      },
      "source": [
        "## **Any Constant Features? They show same value or just one value for all the records in the dataset.**"
      ],
      "id": "e7avb0S27xJp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ijnEMLn71J5"
      },
      "source": [
        "# Checking constant variables\n",
        "constant_features = [col for col in df_maindata.columns if df_maindata[col].nunique() == 1]\n",
        "constant_features"
      ],
      "id": "7ijnEMLn71J5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85jivX1IBOND"
      },
      "source": [
        "# Dropping the constant feature\n",
        "del df_maindata['wicket_keeper_in_team']"
      ],
      "id": "85jivX1IBOND",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Rkjs5MTLHU"
      },
      "source": [
        "## **Correlation**"
      ],
      "id": "c8Rkjs5MTLHU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHDkTocMazYA"
      },
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "ax = sns.heatmap(df_maindata.corr(), annot = True, fmt='.2f', mask = df_maindata.corr() < .65, square = True, lw=0.2,linecolor='black' , cmap = 'copper_r')\n",
        "plt.title(\"Heatmap of Correlation\",fontsize = 20)\n",
        "plt.xlabel(\" \")\n",
        "plt.ylabel(\" \")\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.show();"
      ],
      "id": "SHDkTocMazYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu3WhYGJTzWz"
      },
      "source": [
        "Observations:\n",
        "- Wicket_keeper_in_team has only one value. Hence we can drop that variable\n",
        "- Multicollinearity exists between player_highest_wicket and (audience number and extra bowls bowled) at 0.65 as threshold.\n",
        "- Drop audience number and extra bowls bowled"
      ],
      "id": "Bu3WhYGJTzWz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fSTFaGXFzLs"
      },
      "source": [
        "df_maindata.drop(['audience_number', 'extra_bowls_bowled'], axis = 1, inplace=True)"
      ],
      "id": "3fSTFaGXFzLs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZEBqkVkZjo6"
      },
      "source": [
        "## **Plotting Categorical Fetures**"
      ],
      "id": "FZEBqkVkZjo6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ws2PsOzZihE"
      },
      "source": [
        "sns.countplot('first_selection', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "7Ws2PsOzZihE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A8pb5WqfGSB"
      },
      "source": [
        "sns.countplot('season', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "2A8pb5WqfGSB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgIoOHGtfSnA"
      },
      "source": [
        "sns.countplot('opponent', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "fgIoOHGtfSnA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd0yNWVdgcL0"
      },
      "source": [
        "sns.countplot('match_format', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "Wd0yNWVdgcL0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o_due3Vgizm"
      },
      "source": [
        "sns.countplot('offshore', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "7o_due3Vgizm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_pXK-LSgsLd"
      },
      "source": [
        "sns.countplot('match_light_type', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "P_pXK-LSgsLd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U74baCMSg6M1"
      },
      "source": [
        "sns.countplot('avg_team_age', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "U74baCMSg6M1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M2xSB8l3gI1"
      },
      "source": [
        "Observation:\n",
        "- avg_age_team has outliers. Average age for any team cannot be 12 or 70. Either its a mistake or outliers.\n",
        "- India win most matches in avg_age 30. \n",
        "- Day time matches are beneficial for us."
      ],
      "id": "3M2xSB8l3gI1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6T_0DZJ4bQB"
      },
      "source": [
        "### **Treating the outliers**\n",
        "- **Capping and Flooring the outliers**\n",
        "\n"
      ],
      "id": "V6T_0DZJ4bQB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htb_GFHyi_Hc"
      },
      "source": [
        "percentiles = df_maindata['avg_team_age'].quantile([0.01, 0.99]).values\n",
        "df_maindata['avg_team_age'] = np.clip(df_maindata['avg_team_age'], percentiles[0], percentiles[1])"
      ],
      "id": "Htb_GFHyi_Hc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7B5lw63jQk4"
      },
      "source": [
        "sns.countplot('avg_team_age', hue = 'result' , data = df_maindata)\n",
        "plt.show()"
      ],
      "id": "d7B5lw63jQk4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0H4KFX1hTJ7"
      },
      "source": [
        "for col in df_maindata.columns:\n",
        "  plt.figure(figsize = (12,5))\n",
        "  if df_maindata[col].dtype != 'object':\n",
        "    sns.boxplot(df_maindata[col])\n",
        "    plt.show()"
      ],
      "id": "s0H4KFX1hTJ7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PS_bxMSWajO"
      },
      "source": [
        "## **Let's work with Cardinality**"
      ],
      "id": "8PS_bxMSWajO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEm4B7ecSXJz"
      },
      "source": [
        "for col in df_maindata.columns:\n",
        "  print(col)\n",
        "  print(f\"First 5 Unique Values: {df_maindata[col].unique()[:5]}\")\n",
        "  print(f\"Number of unique values: {df_maindata[col].nunique()}\")\n",
        "\n",
        "  print('\\n')"
      ],
      "id": "fEm4B7ecSXJz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MG4fgRKYgDk"
      },
      "source": [
        "### **Observation:**\n",
        "\n",
        "---\n",
        "- We can One Hot Encode variables with 3 unique values\n",
        "- Drop audience_number as it doesn't contribute much towards the predictions.\n"
      ],
      "id": "1MG4fgRKYgDk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9C4syoBlhzj"
      },
      "source": [
        "useful_cols = [col for col in df_maindata.columns if col not in ['game_number', 'result', 'kfold']]\n",
        "categorical = [col for col in useful_cols if df_maindata[col].dtype == 'object']\n",
        "numerical = [col for col in useful_cols if col not in categorical]"
      ],
      "id": "u9C4syoBlhzj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW7dNE50iGFi"
      },
      "source": [
        "ohe_list = []\n",
        "for col in df_maindata[useful_cols].columns:\n",
        "  if df_maindata[useful_cols][col].nunique() <= 3:\n",
        "    ohe_list.append(col) \n",
        "\n",
        "ohe_list"
      ],
      "id": "RW7dNE50iGFi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xW8y9OXXsUe"
      },
      "source": [
        "for col in ohe_list:\n",
        "  dummies = pd.get_dummies(df_maindata[col], prefix=col)\n",
        "  df_maindata[dummies.columns] = dummies"
      ],
      "id": "9xW8y9OXXsUe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c-lDoCEqFFY"
      },
      "source": [
        "df_maindata.drop(ohe_list, axis = 1, inplace=True )\n",
        "df_maindata.drop('game_number', axis = 1, inplace=True)"
      ],
      "id": "7c-lDoCEqFFY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blovzmnbl0j1"
      },
      "source": [
        "df_maindata['result'] = df_maindata['result'].apply(lambda x: 1 if x == 'Win' else 0)"
      ],
      "id": "Blovzmnbl0j1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlEzmvPRqrhW"
      },
      "source": [
        "useful_cols = [col for col in df_maindata.columns if col not in ['game_number', 'result' ,'kfold']]\n",
        "categorical = [col for col in useful_cols if df_maindata[col].dtype == 'object']\n",
        "numerical = [col for col in useful_cols if col not in categorical]"
      ],
      "id": "jlEzmvPRqrhW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6NvRUZ32VdS"
      },
      "source": [
        "sns.set(rc={'xtick.labelsize':16,'ytick.labelsize':16,'axes.labelsize':16})\n",
        "sns.relplot(x=\"player_highest_run\", y=\"max_run_given_1over\",col=\"first_selection_Bowling\", row=\"max_wicket_taken_1over\", hue='result',  data=df_maindata)\n",
        "plt.show()"
      ],
      "id": "T6NvRUZ32VdS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caMSdGhPooWT"
      },
      "source": [
        "for col in df_maindata.columns:\n",
        "  print(col)\n",
        "  print(f\"First 5 Unique Values: {df_maindata[col].unique()[:5]}\")\n",
        "  print(f\"Number of unique values: {df_maindata[col].nunique()}\")\n",
        "\n",
        "  print('\\n')"
      ],
      "id": "caMSdGhPooWT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Y_bak0B3tV"
      },
      "source": [
        "df, df_test1 = train_test_split(df_maindata, stratify=df_maindata['result'], test_size = 0.15, random_state = 7)"
      ],
      "id": "L_Y_bak0B3tV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I154zlU74tyy"
      },
      "source": [
        "## **HyperTuning first Model**"
      ],
      "id": "I154zlU74tyy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEtKnTzjvNPG"
      },
      "source": [
        "def run(trial):\n",
        "\n",
        "    for fold in range(5):\n",
        "        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "        xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "        ytrain = xtrain.result\n",
        "        yvalid = xvalid.result\n",
        "        \n",
        "        xtrain = xtrain[useful_cols]\n",
        "        xvalid = xvalid[useful_cols]\n",
        "        \n",
        "        train_dicts =xtrain.to_dict(orient='records')\n",
        "        val_dicts = xvalid.to_dict(orient='records')\n",
        "        dv = DictVectorizer(sparse=False)\n",
        "        xtrain = dv.fit_transform(train_dicts)\n",
        "        xvalid = dv.transform(val_dicts)\n",
        "        \n",
        "        # Optuna suggest params\n",
        "\n",
        "\n",
        "        params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 7000, 9000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
        "        'learning_rate': trial.suggest_uniform('learning_rate', 0.001, 0.1),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.001)}\n",
        "        \n",
        "        model_xgb = XGBClassifier(**params, random_state=7)\n",
        "        \n",
        "        \n",
        "        model_xgb.fit(xtrain, ytrain, early_stopping_rounds=300,eval_set=[(xvalid, yvalid)],  verbose=500)\n",
        "        \n",
        "        preds_valid = model_xgb.predict_proba(xvalid)[:, 1]\n",
        "        roc_auc = metrics.roc_auc_score(yvalid, preds_valid)\n",
        "    \n",
        "        \n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(run, n_trials=20)\n",
        "\n",
        "study.best_params"
      ],
      "id": "aEtKnTzjvNPG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VevxS8hIoFgT"
      },
      "source": [
        "\n",
        "df_test = df_test1[useful_cols]\n",
        "final_test_predictions = []\n",
        "final_valid_predictions = {}\n",
        "decisions_valid = []\n",
        "decisions_test = [] \n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test1.copy()\n",
        "    \n",
        "    valid_ids = xvalid.index.values.tolist()\n",
        "\n",
        "    ytrain = xtrain.result\n",
        "    yvalid = xvalid.result\n",
        "    \n",
        "    xtrain = xtrain[useful_cols]\n",
        "    xvalid = xvalid[useful_cols]\n",
        "    xtest = xtest[useful_cols]\n",
        "    \n",
        "    train_dicts = xtrain.to_dict(orient='records')\n",
        "    val_dicts = xvalid.to_dict(orient='records')\n",
        "    test_dicts = xtest.to_dict(orient='records')\n",
        "\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    xtrain = dv.fit_transform(train_dicts)\n",
        "    xvalid = dv.transform(val_dicts)\n",
        "    xtest = dv.transform(test_dicts)\n",
        "    \n",
        "    params = study.best_params\n",
        "    \n",
        "    \n",
        "    model = XGBClassifier(n_estimators=2000,\n",
        "        random_state=7\n",
        "    )\n",
        "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=500)\n",
        "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
        "\n",
        "    test_preds = model.predict_proba(xtest)[:1]\n",
        "\n",
        "    final_test_predictions.append(test_preds)\n",
        "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
        "    roc_auc = metrics.roc_auc_score(yvalid, preds_valid)\n",
        "    print(fold, roc_auc)\n",
        "    scores.append(roc_auc)\n",
        " \n",
        "print(np.mean(scores), np.std(scores))"
      ],
      "id": "VevxS8hIoFgT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o4hSBgF8HSC"
      },
      "source": [
        "## **Confusion Matrix and Classification reports for XGB model.**"
      ],
      "id": "0o4hSBgF8HSC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcuisEXJolHF"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "val_dicts = df_test.to_dict(orient='records')\n",
        "df_test = dv.transform(val_dicts)\n",
        "print(confusion_matrix(df_test1.result, model.predict(df_test)))\n",
        "print(classification_report(df_test1.result, model.predict(df_test)))"
      ],
      "id": "HcuisEXJolHF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNPf4Hc4Lr1f"
      },
      "source": [
        "import xgboost as xgb\n",
        "model.get_booster().feature_names = list(useful_cols)\n",
        "xgb.plot_importance(model.get_booster())"
      ],
      "id": "TNPf4Hc4Lr1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsTTV4ThmZn"
      },
      "source": [
        "from sklearn.ensemble import  RandomForestClassifier"
      ],
      "id": "EKsTTV4ThmZn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcKFckwz8WRl"
      },
      "source": [
        "## **Hyperparameter tuning Random Forest**"
      ],
      "id": "RcKFckwz8WRl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Oaa4cOy9la"
      },
      "source": [
        "def run(trial):\n",
        "\n",
        "    for fold in range(5):\n",
        "        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "        xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "        ytrain = xtrain.result\n",
        "        yvalid = xvalid.result\n",
        "        \n",
        "        xtrain = xtrain[useful_cols]\n",
        "        xvalid = xvalid[useful_cols]\n",
        "        \n",
        "        train_dicts =xtrain.to_dict(orient='records')\n",
        "        val_dicts = xvalid.to_dict(orient='records')\n",
        "        dv = DictVectorizer(sparse=False)\n",
        "        xtrain = dv.fit_transform(train_dicts)\n",
        "        xvalid = dv.transform(val_dicts)\n",
        "        \n",
        "        # Optuna suggest params\n",
        "        params = {\n",
        "        'n_estimators':  trial.suggest_int(\"n_estimators\", 2, 7000),\n",
        "        'max_depth': int(trial.suggest_loguniform('max_depth', 1, 32))}\n",
        "\n",
        "\n",
        "        \n",
        "        model_rf = RandomForestClassifier(**params, random_state=7)\n",
        "        \n",
        "        \n",
        "        model_rf.fit(xtrain, ytrain)\n",
        "        \n",
        "        preds_valid = model_rf.predict_proba(xvalid)[:, 1]\n",
        "        roc_auc = metrics.roc_auc_score(yvalid, preds_valid)\n",
        "    \n",
        "        \n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(run, n_trials=20)\n",
        "\n",
        "study.best_params"
      ],
      "id": "g3Oaa4cOy9la",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r62lenXEhhnt"
      },
      "source": [
        "\n",
        "df_test = df_test1[useful_cols]\n",
        "final_test_predictions = []\n",
        "final_valid_predictions = {}\n",
        "decisions_valid = []\n",
        "decisions_test = [] \n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "    \n",
        "    valid_ids = xvalid.index.values.tolist()\n",
        "\n",
        "    ytrain = xtrain.result\n",
        "    yvalid = xvalid.result\n",
        "    \n",
        "    xtrain = xtrain[useful_cols]\n",
        "    xvalid = xvalid[useful_cols]\n",
        "    \n",
        "    train_dicts = xtrain.to_dict(orient='records')\n",
        "    val_dicts = xvalid.to_dict(orient='records')\n",
        "    test_dicts = xtest.to_dict(orient='records')\n",
        "\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    xtrain = dv.fit_transform(train_dicts)\n",
        "    xvalid = dv.transform(val_dicts)\n",
        "    xtest = dv.transform(test_dicts)\n",
        "    \n",
        "    \n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        random_state=7, \n",
        "        n_estimators=103,\n",
        "        max_depth = int(31.939959712387637)\n",
        "    )\n",
        "    model.fit(xtrain, ytrain)\n",
        "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
        "\n",
        "    test_preds = model.predict_proba(xtest)[:, 1]\n",
        "\n",
        "    final_test_predictions.append(test_preds)\n",
        "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
        "    roc_auc = metrics.roc_auc_score(yvalid, preds_valid)\n",
        "    print(fold, roc_auc)\n",
        "    scores.append(roc_auc)\n",
        " \n",
        "print(np.mean(scores), np.std(scores))"
      ],
      "id": "r62lenXEhhnt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aXpwGeHiCIR"
      },
      "source": [
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "#do code to support model\n",
        "#\"data\" is the X dataframe and model is the SKlearn object\n",
        "\n",
        "feats = {} # a dict to hold feature_name: feature_importance\n",
        "for feature, importance in zip(df_maindata.columns, model.feature_importances_):\n",
        "    feats[feature] = importance #add the name/value pair \n",
        "\n",
        "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
        "\n",
        "(importances.sort_values(by='Gini-importance', ascending = False)).plot(kind='barh')"
      ],
      "id": "9aXpwGeHiCIR",
      "execution_count": null,
      "outputs": []
    }
  ]
}